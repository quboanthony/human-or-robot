# facebook-recruiting-iv-human-or-bot
- Udacity capstone project
- by: Bo QU

# In python 3
- data_investigation.ipynb
Jupyter notebook file with codes of Data Exploration.
- human-or-robot.ipynb
Jupyter notebook file for the main codes for solving the project. 

# Packages:
- pandas
- numpy
- math
- scikit-learn
- dmlc xgboost
- seaborn
- matplotlib
- scipy

# Data set
Data set from kaggle project website: https://www.kaggle.com/c/facebook-recruiting-iv-human-or-bot/data

# References links:
[1] Garbage in, garbage out: https://en.wikipedia.org/wiki/Garbage_in,_garbage_out
[2] Receiver operating characteristic: https://en.wikipedia.org/wiki/Receiver_operating_characteristic
[3] Kaggle project website: https://www.kaggle.com/c/facebook-recruiting-iv-human-or-bot
[4] Population stability index: https://www.listendata.com/2015/05/population-stability-index.html
[5] Numpy log: https://docs.scipy.org/doc/numpy/reference/generated/numpy.log.html
[6] MinMaxScaler: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html
[7] XGBoost: https://xgboost.readthedocs.io/en/latest/#
[8] Gradient Boosting: https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/
[9] Random Forest: https://en.wikipedia.org/wiki/Random_forest
[10] Adaboost: https://en.wikipedia.org/wiki/AdaBoost
[11] Extra-Trees: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.65.7485&rep=rep1&type=pdf
[12] Scikit-learn: http://scikit-learn.org/stable/index.html
[13] dmlc XGboost: https://github.com/dmlc/xgboost
[14] Seaborn: http://seaborn.pydata.org/
[15] Matplotlb: https://matplotlib.org/
[16] Population stability index: http://ucanalytics.com/blogs/population-stability-index-psi-banking-case-study/
[17] Guide to parameter tuning in XGBoost: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/
[18] Kaggle ensembling guide: https://mlwave.com/kaggle-ensembling-guide/


